\documentclass[a4paper]{report}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{eurosym}
\usepackage{fancyhdr}%encabezado y pie de página
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue]{hyperref}
\setcounter{secnumdepth}{5}
\usepackage[spanish]{babel}
\setcounter{tocdepth}{5}
\usepackage{colortbl}%para colorear tablas
\usepackage{tabularx}
\usepackage{pdfpages}%para incluir documentos pdf
\usepackage{placeins}%para poner barrera y no pasen de secciones los elemntos flotantes
\usepackage{longtable}
\usepackage{multirow} %para juntar varias filas en una tabla

\author{Andoni Martín Reboredo \\ David Ramirez Ambrosi}
\title{\begin{center}
\textbf{\Huge{Práctica 6, Clustering}} \\ \includegraphics{./Figuras/KMeans-density-data.png}\\  \textbf{Minería de datos}
\end{center}}
\date{\today}



\pagestyle{fancy}
\rhead{
\textbf{Minería de datos} \hfill Práctica 6: Clustering
}

\lhead{}

%colores
\definecolor{azul}{RGB}{0,240,255}
\definecolor{amarillo}{RGB}{255,240,0}
\definecolor{rojo}{RGB}{255,198,198}

%Separación entre párrafos
\setlength{\parskip}{4mm}

\begin{document}
\maketitle

\thispagestyle{empty}%para evitar enumeración de la página de la portada y del índice
\newpage
\tableofcontents%índice
\thispagestyle{empty}
\newpage

\listoffigures%índice de figuras
\thispagestyle{empty}
\newpage

\setcounter{page}{1}%Para reinizar el contador de páginas en la página deseada


\chapter{Introducción}

El presente documento constituye el resultado de la práctica realizada en base a la implementación del algoritmo de clasificación no supervisada \textbf{K-Means clustering}. Este algoritmo trata el agrupamiento de un conjunto de instancias en base a su proximidad con las demás instancias contenidas en el espacio de muestra proporcionado al algoritmo para su ejecución.

Dentro del algoritmo cabe el estudio de diferentes variaciones en los distintos parámetros de que dispone. Nosotros hemos considerado variaciones sobre dos parámetros, el método de cálculo de la distancia entre los distintos elementos que posee el cluster y la inicialización de los distintos clusters. Esta inicialización servirá como base de las sucesivas iteraciones que conforman el algoritmo.

	\section{Clasificación no-supervisada}
	
	La clasificación no supervisada es aquella que se lleva a cabo mediante el estudio de las diversas instancias que conforman el espacio de aplicación del algoritmo sin que estas instancias tengan que estar previamente clasificadas dentro de una clase \cite{clase}.
	
	Se trata de una técnica de exploración de los datos en la que se intentan detectar estas clases desconocidas. Dependiendo de el algoritmo de clasificación utilizado, el número de clases debe o no ser especificado. Por ejemplo, en el algoritmo en que se basa este trabajo debe ser especificado, sin embargo en técnicas de \textbf{clusterig jerárquico} no.
	
	\section{Objetivo}
	
	Esta práctica tiene como objetivo principal la comprensión de los procesos internos que realiza un algoritmo de agrupamiento cualquiera como puede ser el K-Means clustering. El aprendizaje se realizará de forma práctica a través de la implementación del algoritmo K-Means clustering junto con diversas opciones con las que realizar algunos pasos del mismo, como son el uso de métricas o inicializaciones del algoritmo diferentes.	Estas variaciones requieren que el algoritmo sea entendido plenamente para poder hacer contribuciones que tengan utilidad para la realización del proceso.
	
\chapter{Algoritmo}

	\section{K-means, algoritmo principal}
	
	\begin{verbatim}
	inicializar
	divergencia = infinito 
	
	Mientras(numiteraciones <= iteracionesIndicadas AND divergencia < delta)
	{
	    centroides = centroidesNuevos 
	
	    calcularPertenencias
	    centroidesNuevos = calcularNuevosCentroides
		
	    calcularDivergencia(centroidesNuevos) 
	}
	\end{verbatim}
	
	\section{Subrutina inicialización}
		\subsection{Inicialización aleatoria}
			\begin{verbatim}
			Para cada dimensión
			{
			   mientras extraiga una instancia ya evaluada
			   {
			      extraigo una instancia nueva
			   }
			   añado la instancia extraida a las evaluadas
			   establezco la instancia como centroide de un cluster
			}
			\end{verbatim}
		
		\subsection{Pertenencia aleatoria}
			\begin{verbatim}
			Mientras haya instancias que asignar
			{
			   Calculo un número de cluster aleatorio
			   Extraigo la siguiente instancia
			   Añado la instancia al cluster aleatorio
			}
			Calculo los centroides del cluster
			\end{verbatim}
		
		\subsection{División de espacio}
			\begin{verbatim}
			Obtengo los rangos máximos y mínimos de cada subespacio
			Mientras no haya creado k divisiones
			{
			   Mientras no haya establecido todos los atributos(recorrido los subespacios)
			   {
			      Divido el subespacio en K
			      Asigno el centro del subespacio dividido correspondiente al índice del bucle
			   }
			   Añado el centroide resultante de dividir el espacio
			}
			\end{verbatim}
		
		\subsection{Generación aleatoria de codewords}
		\begin{verbatim}
		Obtengo los máximos y mínimos de cada dimensión
		Para cada cluster
		{
		   Evaluo cada dimensión
		   {
		      Calculo un valor aleatorio para ese centroide en esa dimensión
		   }
		   Añado el centroide generado al cluster
		}
		\end{verbatim}
	\section{Subrutina calcularPertenencias}
	
		\begin{verbatim}
		Crear nuevos clusters 
		
		Para cada instancia
		{
		    Para cada centroide
		    {
		        distancia entre la instancia y cada cluster
		        Guardamos los mínimos 
		    }    
		    Para cada centroide obtenido
		        Guardamos la instancia en el cluster correspondiente al centroide
		}
		\end{verbatim}
	
	\section{Subrutina calcularCentroides}
	
		\begin{verbatim}
		Para cada cluster
		
		   Calcular la instancia media
		   
		return nuevosCentroides
		\end{verbatim}
	
	\section{Subrutina calcularDivergencia}
	
		\begin{verbatim}
		Para cada cluster 
		   
		   Calcular la distancia entre el centroide antiguo y el nuevo
		   
		return divergenciaAcumulada
		\end{verbatim}

\chapter{Diseño}

En la figura \ref{fig:clases} se muestra el diagrama de clases final de la aplicación, extraido a partir del código mediante el software \textit{Visual Paradigm}. La especificación de cada uno de los métodos se puede encontrar en la documentación adjunta generada con \textit{Eclipse}, la carpeta doc contiene la \textit{javadoc} generada en forma de \textit{HTMLs} navegables.
	
\begin{figure}[!h]
	\centering
	\includegraphics[width=1.1\textwidth, clip=true,trim=1cm 8cm 1.2cm 1cm]{./Figuras/clases.pdf}
	\caption{Diagrama de clases y paquetes}
	\label{fig:clases}
\end{figure}

\chapter{Resultados experimentales}

	\section{Banco de pruebas para la validación de software y resultados}
	
	\section{Resultados}
	
	\begin{figure}[!h]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		K	&	Aleatoria	&	Pert aleatoria	&	Cent aleatoria	&	Particionada	&	Weka \\
		\hline
		2	&	559.6037	&	555.6380	&	417.3507	&	555.6380 & 3732.1410\\
		\hline
		3	&	726.4665	&	799.9119	&	732.8291	&	759.2235 & 3177.5020\\
		\hline
		4	&	1011.9005	&	975.9922	&	1047.5332	&	730.4880 & 3424.5702\\
		\hline
		5	&	982.6874	&	1220.2895	&	917.7001	&	911.4739 & 2868.2795\\
		\hline
		\end{tabular}
		
		\caption{Resultados para el fichero de pruebas \textit{colon.csv}, \textit{Weka} con valores por defecto salvo \textit{K}}
		\label{res_colon}
	\end{figure}
	
	\begin{figure}[!h]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
		K	&	Aleatoria	&	Pert aleatoria	&	Cent aleatoria	&	Particionada & Weka\\
		\hline
		2	&	4.5291	&	4.5291	&	4.5291	&	4.5291 & 5.0693\\
		\hline
		3	&	5.6385	&	6.9322	&	6.6599	&	5.6385 & 4.0771\\
		\hline
		4	&	7.1510	&	4.1677	&	4.1480	&	4.1677 & 3.2290\\
		\hline
		5	&	4.7109	&	7.3777	&	4.2406	&	4.8980 & 2.77504\\
		\hline
		\end{tabular}
		
		\caption{Resultados para el fichero de pruebas \textit{food.csv}, \textit{Weka} con valores por defecto salvo \textit{K}}
		\label{res_food}
	\end{figure}
	
	\FloatBarrier
	\section{Clasificación supervisada respecto de otro software de referencia}
	\section{Clasigicación supervisada, Iris}
		Para el fichero Iris, sabiendo de antemano que se quieren clasificar tres variedades de esta planta, el algoritmo utilizando la inicialización que escoge como centroides tres instancias aleatorias del espacio muestral consige un acierto de un 88.66\% basándonos en un único experimento.
		
		Los datos para la validación de este resultado se encuentran en la carpeta de resultados proporcianada.
		
	\section{Variabilidad de los resultados}
	
	El uso de generadores de valor aleatorios sin utilizar ningún tipo de mapeo, a diferencia de Weka, hace que la calidad de \textbf{la solución varíe} en exceso de una ejecución a otra. El uso de aleatorios se da en los casos de inicialización aleatoria, pertenencia aleatoria y generación aleatoria de codewords. Este problema no se da en el último tipo de inicialización, división de espacio, ya que ésta generará los mismos k centroides para un mismo conjunto de datos.
	
	Para probar la variabilidad, se ha utilizado el fichero de pruebas food.csv con la inicialización aleatoria y la distancia euclídea generando 4 clusters. Se ha repetido esta misma operación 10000 veces y se han obtenido los resultados siguientes:
	
	\begin{verbatim}
	     Min.:      4.148 
	     1st Qu.:   6.014 
	     Mediana:   6.335 
	     Media:     6.181 
	     3rd Qu.:   7.145 
	     Max.:      7.843
	     Varianza:  1.073
	\end{verbatim}
	
	Los valores del error en las 10000 repeticiones varían en el intervalo [4.148, 7.843], siendo la media 6.181. En la figura \ref{fig:error} se muestran de forma gráfica los resultados mediante un histograma con la densidad de los diferentes valores. A pesar de el uso  de aleatorios, la varianza en las 10000 pruebas extraídas no es excesivamente grande.
	
	\begin{figure}[!h]
		\centering
		\includegraphics[width=\textwidth]{./Figuras/Densidad.png}
		\caption{Histograma y frecuencia de los errores obtenidos}
		\label{fig:error}
	\end{figure}
	
	\section{Análisis crítico y discusión de resultados}
	
	\section{Rendimiento del software}

\chapter{Conclusiones}

	\section{Motivación para la realización de \textit{Clustering}}
	
	Explorar un conjunto de instancias con el objetivo de 
	
	\section{Conclusiones de los resultados}
	
	\section{Conclusiones generales}
	
	El tiempo invertido en el proyecto ha sido mucho mayor conforme se acercaba la fecha de entrega. Debemos mejorar en organización, especialmente al principio de la práctica, donde un diseño poco especificado con ciertas cosas \textit{"en el aire"} nos llevaron a diseñar al implementar.
	
	También el hecho de probar y perfeccionar el funcionamiento de \textbf{todo} el código antes de comenzar con la extracción de resultados experimentales nos limitó en el análisis de los mismos y en la retroalimentación del algoritmo implementado.
	
	Resumiendo, hay que mejorar la planificación, dividir el proyecto en partes para poder mejorarlo incrementalmente.
	
	Pese a los problemas, la solución implementada ofrece una variedad bastante amplia de parámetros posibles a utilizar, teniendo 4 tipos de inicialización, dos métricas diferentes - en el caso de la métrica Minkowski ofrece otro parámetro más que variar- y la posibilidad de controlar el número de iteraciones tanto por la especificación de un maximo de vueltas, como por la especificación del margen de variación que se debe alcanzar hasta dar por válidos los centroides identificados.
	
	\section{Propuestas de mejora}
	
	La entrada a nuestro programa es un factor un tanto restrictivo en el sentido de que el único tipo de fichero soportado es el \textbf{CSV}. Inicialmente, la intención era implementar también la carga de ficheros \textbf{ARFF}, que no ha sido posible hacerla por falta de planificación principalmente.
	
	En cuanto a inicializaciones, hemos implementado 4 tipos diferentes. De los tres, el correspondiente a la división de espacio es el que más puede mejorar, ya que para su implementación no hemos llegado a consultar bibliografía extra.
	
	La \textbf{estimación del error} es otro apartado en el que nos ha quedado duda, ya que el proceso de cálculo utilizado no ha sido el mismo que el usado por Weka y nos dificultaba la comparación de ambos algoritmos utilizando esta medida.
	
	Otra restricción se da por el tipo de datos tratados, el algoritmo solo es capaz de lidiar con atributos de tipo numérico, siendo imposible realizar la carga de instancias que contengan valores no numéricos. De hecho, algunos de los ficheros han tenido que ser preprocesados para poder trabajar con ellos.
	
	Otro problema ya arrastrado de trabajos anteriores, es la \textbf{presentación de resultados}. No en cuanto a la información presentada, sino a como se presentan concretamente los\textbf{ valores reales}, que deberían ser redondeados a, por ejemplo, 3 decimales. Esto permitiría que los informes generados sean más fáciles de leer e interpretar.

%Bibliografía

\newpage
\bibliographystyle{plain}

\bibliography{mdp6}

\newpage


\chapter{Valoración subjetiva}
	
	\section*{Alcance de objetivos}
	
	\section*{Utilidad de la tarea}
	
	\section*{Dificultad}
	
	\section*{Tiempo de trabajo}
	
	\section*{Sugerencias de mejora}
	
	\section*{Críticas}

\end{document}